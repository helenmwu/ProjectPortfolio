{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.cluster import KMeans\n",
        "import cv2\n",
        "import math"
      ],
      "metadata": {
        "id": "WwPQbumiJECV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 1**"
      ],
      "metadata": {
        "id": "z8Tv3nAaIzLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "df.set_index('customerID', inplace=True)\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')"
      ],
      "metadata": {
        "id": "bcyXXW9uJPUD"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create another instance of dataframe to test another preprocessing method"
      ],
      "metadata": {
        "id": "mKXp7g6B7XNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "df2.set_index('customerID', inplace=True)\n",
        "df2['TotalCharges'] = pd.to_numeric(df2['TotalCharges'], errors='coerce')"
      ],
      "metadata": {
        "id": "EPK9OEq47VQY"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop([\"Churn\"], axis=1)\n",
        "y = df[\"Churn\"]\n",
        "\n",
        "X2 = df2.drop([\"Churn\"], axis=1)\n",
        "y2 = df2[\"Churn\"]"
      ],
      "metadata": {
        "id": "dovvxZyQUVKO"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=16)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.25, random_state=16)"
      ],
      "metadata": {
        "id": "g4VMrOc6UCbt"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For preprocessing, I performed One-Hot Encoding for all the categorical variables. I felt this was appropriate for the problem because if I simply replaced all values with 0,1,2,.. etc., this would suggest a natural ordering between the feature values which isn't true. For example, there is nothing that suggests Fiber Optic Internet Service is better than Cable. With One-Hot Encoding, dummy variables are created, with additional columns for each category, so that a 1 suggests the presence of that category, and 0 the absence. For the missing values in the numeric columns, for one instance,I chose to replace all the missing values with zeros. For the other instance, I decided to drop any columns with missing values. For replacing missing values with zeroes, this felt appropriate for the problem, since I noticed all the missing values only occured in the columns with numerical features. Since I do not want to lose effect that this feature has on whether or not the customer would leave, I chose to just replace the missing values with zero. For the instance where I dropped columns that contained missing values, I felt this would be a good approach because due to lack of domain knowledge, I did not want to erroneously fill in a value because it might introduce bias to my model and not be representative of the actual relationship between the variables.\n",
        "In addition, I chose to normalize only the features that were not categorical. Since total charges were on a different scale and thus a lot larger than values for tenure, I decided that scaling all numeric columns would allow my model to perform better and prevent bias from some variables being in larger ranges."
      ],
      "metadata": {
        "id": "Oc45Y-Evs3O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#replace the yes and no values with 1 and 0\n",
        "X_train = X_train.replace({'Yes': 1, 'No': 0})\n",
        "X_test = X_test.replace({'Yes': 1, 'No': 0})\n",
        "X_train2 = X_train2.replace({'Yes': 1, 'No': 0})\n",
        "X_test2 = X_test2.replace({'Yes': 1, 'No': 0})\n",
        "categorical_columns = [\n",
        "    'gender', 'InternetService', 'MultipleLines',\n",
        "    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "    'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
        "    'Contract', 'PaymentMethod'\n",
        "]\n",
        "\n",
        "# One-hot encode categorical columns for each DataFrame\n",
        "X_train = pd.get_dummies(X_train, columns=categorical_columns, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, columns=categorical_columns, drop_first=True)\n",
        "X_train2 = pd.get_dummies(X_train2, columns=categorical_columns, drop_first=True)\n",
        "X_test2 = pd.get_dummies(X_test2, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Ensure all DataFrames have the same columns by reindexing\n",
        "X_train, X_test = X_train.align(X_test, join='outer', axis=1, fill_value=0)\n",
        "X_train2, X_test2 = X_train2.align(X_test2, join='outer', axis=1, fill_value=0)\n",
        "\n",
        "#Transform false values to 0 and true values to 1 as a result of One-hot encoding\n",
        "X_train[X_train.select_dtypes(include='bool').columns] = X_train.select_dtypes(include='bool').astype(int)\n",
        "X_test[X_test.select_dtypes(include='bool').columns] = X_test.select_dtypes(include='bool').astype(int)\n",
        "X_train2[X_train2.select_dtypes(include='bool').columns] = X_train2.select_dtypes(include='bool').astype(int)\n",
        "X_test2[X_test2.select_dtypes(include='bool').columns] = X_test2.select_dtypes(include='bool').astype(int)\n",
        "\n",
        "\n",
        "numerical_columns = [\n",
        "    'tenure',\n",
        "    'MonthlyCharges',\n",
        "    'TotalCharges'\n",
        "]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "## for first data frame only, replace missing values with zeroes\n",
        "for column in numerical_columns:\n",
        "    X_train[column] = X_train[column].fillna(0)\n",
        "    X_test[column] = X_test[column].fillna(0)\n",
        "    ## for both data frames, scale the numerical columns\n",
        "    X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
        "    X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
        "    X_train2[numerical_columns] = scaler.fit_transform(X_train2[numerical_columns])\n",
        "    X_test2[numerical_columns] = scaler.transform(X_test2[numerical_columns])\n",
        "\n",
        "\n",
        "\n",
        "#for second data frame only, drop columns with missing values\n",
        "X_train2.dropna(inplace=True, axis = 1)\n",
        "X_test2.dropna(inplace=True, axis = 1)\n",
        "\n",
        "\n",
        "##for both data frames, replace the yes and no values with 0 and 1\n",
        "y_train = y_train.replace({'Yes': 1, 'No': 0})\n",
        "y_train2 = y_train2.replace({'Yes': 1, 'No': 0})\n",
        "y_test = y_test.replace({'Yes': 1, 'No': 0})\n",
        "y_test2 = y_test2.replace({'Yes': 1, 'No': 0})\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4noOTviTYgX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c437daf-0a6b-4289-ee47-bba3414479e0"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-112-0d6f6237fa7b>:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  X_train = X_train.replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-112-0d6f6237fa7b>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  X_test = X_test.replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-112-0d6f6237fa7b>:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  X_train2 = X_train2.replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-112-0d6f6237fa7b>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  X_test2 = X_test2.replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-112-0d6f6237fa7b>:56: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_train = y_train.replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-112-0d6f6237fa7b>:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_train2 = y_train2.replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-112-0d6f6237fa7b>:58: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_test = y_test.replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-112-0d6f6237fa7b>:59: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_test2 = y_test2.replace({'Yes': 1, 'No': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(random_state=16, max_iter = 5000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "logreg2 = LogisticRegression(random_state=16, max_iter = 5000)\n",
        "logreg2.fit(X_train2, y_train2)\n",
        "y_pred2 = logreg2.predict(X_test2)"
      ],
      "metadata": {
        "id": "z8PRKPAXUx_V"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Metrics for Missing Values Replaced with Zeroes\")\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(\"Recall (Sensitivity):\", recall)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1-Score:\", f1)\n",
        "\n",
        "cv_scores = cross_val_score(logreg, X_train, y_train, cv=5)\n",
        "mean_cv_score = cv_scores.mean()\n",
        "print(\"Mean Cross-Validation Score:\", mean_cv_score)\n",
        "\n",
        "roc_auc = metrics.roc_auc_score(y_test, logreg.predict(X_test))\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Metrics for Columns with Missing Values Dropped\")\n",
        "\n",
        "accuracy = accuracy_score(y_test2, y_pred2)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test2, y_pred2)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test2, y_pred2)\n",
        "print(\"Recall (Sensitivity):\", recall)\n",
        "\n",
        "f1 = f1_score(y_test2, y_pred2)\n",
        "print(\"F1-Score:\", f1)\n",
        "\n",
        "cv_scores = cross_val_score(logreg, X_train2, y_train2, cv=5)\n",
        "mean_cv_score = cv_scores.mean()\n",
        "print(\"Mean Cross-Validation Score:\", mean_cv_score)\n",
        "\n",
        "roc_auc = metrics.roc_auc_score(y_test2, logreg2.predict(X_test2))\n",
        "print(\"ROC-AUC Score:\", roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W3i-m3_w2Os",
        "outputId": "9d18818a-002d-49ab-9eff-6883a95f7805"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Missing Values Replaced with Zeroes\n",
            "Accuracy: 0.7995457126632595\n",
            "Precision: 0.6259168704156479\n",
            "Recall (Sensitivity): 0.5614035087719298\n",
            "F1-Score: 0.5919075144508671\n",
            "Mean Cross-Validation Score: 0.8031055589002609\n",
            "ROC-AUC Score: 0.7220810647307925\n",
            "\n",
            "\n",
            "Metrics for Columns with Missing Values Dropped\n",
            "Accuracy: 0.7989778534923339\n",
            "Precision: 0.625615763546798\n",
            "Recall (Sensitivity): 0.5570175438596491\n",
            "F1-Score: 0.5893271461716937\n",
            "Mean Cross-Validation Score: 0.8019699119864683\n",
            "ROC-AUC Score: 0.7202712240371042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bayes = GaussianNB()\n",
        "bayes.fit(X_train, y_train)\n",
        "y_pred = bayes.predict(X_test)\n",
        "\n",
        "bayes2 = GaussianNB()\n",
        "bayes2.fit(X_train2, y_train2)\n",
        "y_pred2 = bayes2.predict(X_test2)"
      ],
      "metadata": {
        "id": "0WM_B9mvjOz5"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Metrics for Missing Values Replaced with Zeroes\")\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(\"Recall (Sensitivity):\", recall)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1-Score:\", f1)\n",
        "\n",
        "cv_scores = cross_val_score(bayes, X_train, y_train, cv=5)\n",
        "mean_cv_score = cv_scores.mean()\n",
        "print(\"Mean Cross-Validation Score:\", mean_cv_score)\n",
        "\n",
        "roc_auc = metrics.roc_auc_score(y_test, bayes.predict(X_test))\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Metrics for Columns with Missing Values Dropped\")\n",
        "\n",
        "accuracy = accuracy_score(y_test2, y_pred2)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test2, y_pred2)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test2, y_pred2)\n",
        "print(\"Recall (Sensitivity):\", recall)\n",
        "\n",
        "f1 = f1_score(y_test2, y_pred2)\n",
        "print(\"F1-Score:\", f1)\n",
        "\n",
        "cv_scores = cross_val_score(logreg, X_train2, y_train2, cv=5)\n",
        "mean_cv_score = cv_scores.mean()\n",
        "print(\"Mean Cross-Validation Score:\", mean_cv_score)\n",
        "\n",
        "roc_auc = metrics.roc_auc_score(y_test2, logreg2.predict(X_test2))\n",
        "print(\"ROC-AUC Score:\", roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_swaQ4BkOey",
        "outputId": "124c1906-fac3-4c15-d1fe-4517d69c3419"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Missing Values Replaced with Zeroes\n",
            "Accuracy: 0.676320272572402\n",
            "Precision: 0.43817787418655096\n",
            "Recall (Sensitivity): 0.8859649122807017\n",
            "F1-Score: 0.5863570391872278\n",
            "Mean Cross-Validation Score: 0.6800480562483873\n",
            "ROC-AUC Score: 0.7445150231901594\n",
            "\n",
            "\n",
            "Metrics for Columns with Missing Values Dropped\n",
            "Accuracy: 0.6655309483248154\n",
            "Precision: 0.4291799787007455\n",
            "Recall (Sensitivity): 0.8837719298245614\n",
            "F1-Score: 0.5777777777777777\n",
            "Mean Cross-Validation Score: 0.8019699119864683\n",
            "ROC-AUC Score: 0.7202712240371042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Comparison**\n",
        "To first compare how different pre-processing methods affected the model performance, we see that for each model, it produced similar results. However, for the mean cross validation score in Naive Bayes, we received different values, which will be discussed further. For accuracy, the Logistic Regression model received an accuracy score of .79 and the Naive Bayes model received an accuracy score of .67. This means that when given the predictors, the Logistic Regression model did a better of job of predicting a customer as one who would leave the service and they did, or a customer as one who would not leave the service and they did not (true positive and true negatives). For precision, the Logistic Regression model also showed a higher precision with .635 (as opposed to the Naive Bayes model's precision of .456) which shows the percentage of churns that were correctly predicted. Since Naive Bayes model has a precision of less than half, that means it had more false positive cases (predicting a churn when there wasn't one), than true positives (predicting a churn and the customer did leave the service). For recall, the Naive Bayes model had a better score of .842. This means that this model had a higher amount of true positives (predicting a churn and there was one), than false negatives (predicting a customer would not leave, but they did). The Logistic Regression model had a slightly better F1 score, with .5986 as opposed to the Naive Bayes' model of .592, but both are not very high. Since the F1 score is a combination of how good the precision and recall was, since the Logistic Regression model had a better precision, but the Naive Bayes had a better recall, this makes sense why the F1 scores are pretty similar to each other. For the mean cross validation score of model, this aligned with the results from the accuracy, with the Logistic Regression model showing a better model accuracy. The mean cross validation score in the Naive Bayes model provided surprising results in terms of the differences in how they were pre-processed. The model that dropped columns with missing values had a mean cross validation score of around .80, while the model for missing values replaced with zeroes had a mean cross validation score of .70. This may mean that when columns with missing values are dropped, it is able to perform better on different subsets of the data. The mean cross validation scores for the Logistic Regression model were similar for the two different pre-processing methods, around .80. In addition, the ROC AUC score tells how well a model does at distinguishing between positive and negative classes. The two models had a similar ROC AUC score of around 70%. Based off of this, the Logistic Regression model is more suited for this dataset due to the higher accuracy, but the user should be mindful that it will predict a high amount of false negatives. In addition, the Logistic Regression model had a higher mean cross-validation score than the Naive Bayes model. Since the mean cross-validation score is calculated from different splits on the data, it is probably a better indicator of how the model will perform on the data, rather than any one of the other metrics alone.\n"
      ],
      "metadata": {
        "id": "gPJcUnmCYBvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Look at LogReg Coefficients to compare magnitudes of impact\n",
        "coefficients = logreg.coef_[0]\n",
        "coef_df = pd.DataFrame(zip(X_train.columns, coefficients), columns=['Feature', 'Coefficient'])\n",
        "#print(coef_df.sort_values(by='Coefficient', ascending=False))\n",
        "\n",
        "#To interpret the Naive Bayes model\n",
        "# Look at mean values for each feature and their associated class probabilities\n",
        "feature_means = bayes.theta_  # Shape (n_classes, n_features)\n",
        "feature_summary = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Means (Class 0)': feature_means[0],\n",
        "    'Means (Class 1)': feature_means[1],\n",
        "\n",
        "})\n",
        "\n",
        "#print(feature_summary)"
      ],
      "metadata": {
        "id": "fJPZmFfvJA4v"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights Gained**\n",
        "Since the Logistic Regression from the two different pre-processing steps had similar performance metrics, I will only look at the coefficients for one of them. The magnitude of a coefficient is often a good indicator for the effect it had on the log odds of the outcome, the customer churn in this case. For the Logistic Regression model, the \"Total Charges\" and \"Internet Service - Fiber Optic\" variables had the biggest impact on increasing the log odds chances of a customer leaving the service. This means further investigation should be done to see if total charges can be reduced to lower the chances of them leaving the service and also why Fiber Optic Internet Service customers are most dissatisfied.\"Tenure\" and the \"Contract\" variable had the biggest impact on decreasing the log odds of a customer leaving the service. The tenure and contract variables makes sense, as the longer a customer has stayed with Telco, the less likely they are to leave. Since \"Total Charges\" was dropped in the second preprocessing instance, upon further investigation to the coefficients for that model, it looks the exact same just missing the total charges variable.\n",
        "From the Naive Bayes model, I chose to see the mean for the feature in the yes and no classes for churn. The results from this aligned with the results from the Logistic Regression model, where higher means for TotalCharges were associated with the customers who did leave the service."
      ],
      "metadata": {
        "id": "QEM2wpWwL3aU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2**"
      ],
      "metadata": {
        "id": "I91LX36mX96Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('test_image.png')\n",
        "height, width, channels = np.shape(img)\n",
        "pixels = img.reshape(height * width, channels)"
      ],
      "metadata": {
        "id": "kPVT_sLk0Wej"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After getting the centroids from using the kmeans algorithm from sci-kit learn, I then calculated the euclidean distance between each pixel and the centroids to choose which color to assign that pixel to. I felt that Euclidean distance was an appropriate measure because since these are all on the same scales for the different values of RGB."
      ],
      "metadata": {
        "id": "d7jZx8slS24J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def img_kmeans(k, img):\n",
        "  height, width, channels = np.shape(img)\n",
        "  pixels = img.reshape(height * width, channels)\n",
        "  kmeans = KMeans(n_clusters = k)\n",
        "  kmeans.fit(pixels)\n",
        "  colors = kmeans.cluster_centers_.astype(int)\n",
        "  new = np.empty_like(img)\n",
        "\n",
        "  for i in range(width):\n",
        "    for j in range(height):\n",
        "      pixel = img[j][i]\n",
        "      #calculate this distance with each centroid\n",
        "      newValue = colors[0]\n",
        "      min_distance = math.inf\n",
        "      for centroid in colors:\n",
        "        euclidean = np.linalg.norm(centroid - pixel)\n",
        "        if euclidean < min_distance:\n",
        "          newValue = centroid\n",
        "          min_distance = euclidean\n",
        "      new[j][i] = newValue # Assign a new value to the pixel\n",
        "\n",
        "  return new\n"
      ],
      "metadata": {
        "id": "uZOroYLX9HwA"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('test_image.png')\n",
        "new = img_kmeans(2, img)\n",
        "cv2.imwrite('new_image.png', new)\n",
        "new"
      ],
      "metadata": {
        "id": "GT1f_kjJ96Sj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "cf3ddd9d-ba9e-4fc2-a827-5a8b34ba2526"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]],\n",
              "\n",
              "       [[131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]],\n",
              "\n",
              "       [[131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]],\n",
              "\n",
              "       [[ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]],\n",
              "\n",
              "       [[ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-ac93d673-c38d-446a-917f-d9d086bd98ca\" class=\"ndarray_repr\"><pre>ndarray (128, 128, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]],\n",
              "\n",
              "       [[131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]],\n",
              "\n",
              "       [[131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        [131, 173, 202],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]],\n",
              "\n",
              "       [[ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]],\n",
              "\n",
              "       [[ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        ...,\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52],\n",
              "        [ 41,  47,  52]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-ac93d673-c38d-446a-917f-d9d086bd98ca button').onclick = (e) => {\n",
              "        document.querySelector('#id-ac93d673-c38d-446a-917f-d9d086bd98ca').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-ac93d673-c38d-446a-917f-d9d086bd98ca button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import structural_similarity as ssim"
      ],
      "metadata": {
        "id": "G1_KiWUdGR7-"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "err = [0] * 20\n",
        "img = cv2.imread('test_image.png')\n",
        "for k in range(1,21):\n",
        "  new = img_kmeans(k, img)\n",
        "  similarity = ssim(img, new, win_size = 3, multichannel = True)\n",
        "  err[k-1] = similarity\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bScBuh54Amib"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "k_values = list(range(1, 21))\n",
        "\n",
        "plt.bar(k_values, err, color='skyblue')\n",
        "plt.title('Number of Clusters (k) vs Similarity')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Similarity')\n",
        "plt.xticks(k_values)\n",
        "plt.grid(axis='y')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "gc2c8GIYDbjN",
        "outputId": "08f655cc-2f8f-4365-f6e5-957d10099b16"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To experiment with different values of k, I decided to use structural similarity from skimage.metrics to evaluate how similar the compressed image is to the original image. This function computes the similarities between luminance, constrast, and structure which all contribute to the way we perceive images. The values for ssim range between -1 and 1, with -1 represeting perfect dissimilarity and 1 being basically identical. We see that as we increase the number of clusters, there initially is a huge jump, but then the increase in similarity starts to taper off. It is still becoming closer to 1, but not much of a difference. For this problem, I would say around 10 clusters is enough. Since the original test image does not have a huge variety of colors, 10 clusters would be enough to represent the image well."
      ],
      "metadata": {
        "id": "8OKgDrZCJQ0Z"
      }
    }
  ]
}